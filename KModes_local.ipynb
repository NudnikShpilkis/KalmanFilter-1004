{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClusterMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def standardize(labels):\n",
    "#Standardize numerical feature\n",
    "    return (labels-labels.mean())/labels.std()\n",
    "\n",
    "def mode2(a, axis=0, val=False):\n",
    "#Return mode or mode freq of an array\n",
    "#code based on scipy.stats.mode\n",
    "    scores = np.unique(np.ravel(a))      \n",
    "    testshape = list(a.shape)\n",
    "    testshape[axis] = 1\n",
    "    oldmostfreq = np.zeros(testshape)\n",
    "    oldcounts = np.zeros(testshape)\n",
    "\n",
    "    for score in scores:\n",
    "        template = (a == score)\n",
    "        counts = np.expand_dims(np.sum(template, axis),axis)\n",
    "        mostfrequent = np.where(counts > oldcounts, score, oldmostfreq)\n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "        oldmostfreq = mostfrequent\n",
    "\n",
    "    return oldcounts[0] if val else mostfrequent[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv('data/avir-tzek.tsv', sep='\\t')\n",
    "a = a.round(1)\n",
    "a2 = a.dropna().copy()\n",
    "\n",
    "for col in a2:\n",
    "    typ = str(a2[col].dtype)\n",
    "    if typ in ['int', 'int32', 'int64','float', 'float32', 'float64']:\n",
    "        a2[col] = standardize(a2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.read_csv('data/h3zm-ta5h.tsv', sep='\\t')\n",
    "c = c.round(1)\n",
    "c2 = c.dropna().copy()\n",
    "\n",
    "for col in c2:\n",
    "    typ = str(c2[col].dtype)\n",
    "    if typ in ['int', 'int32', 'int64','float', 'float32', 'float64']:\n",
    "        c2[col] = standardize(c2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "#Feature subclass for better use with KModes\n",
    "    def __init__(self, featType, labels):\n",
    "        #values in array form and feature dtype\n",
    "        self.vals, self.type = labels, featType\n",
    "        #unique values, their orig indices and counts\n",
    "        vals, inds, counts = np.unique(self.vals, return_inverse=True, return_counts=True)\n",
    "        #Feature dictionary for use in itialization\n",
    "        self.valDict = {v:c for v,c in  zip(vals, counts)}\n",
    "        #frequency of values in orig indices\n",
    "        self.valFreq = counts[inds]\n",
    "        return\n",
    "    \n",
    "    def getCenter(self, cntrMask):\n",
    "    #Get center of feature in given centroid\n",
    "        #Mean for num features\n",
    "        if self.type==float:\n",
    "            return self.vals[cntrMask].mean()\n",
    "        #Mode for cat features\n",
    "        else:\n",
    "            return mode2(self.vals[cntrMask], val=False)        \n",
    "    \n",
    "    def getSimilarity(self, cntr, cntrdMask=None):\n",
    "    #Given centroid center, get dissimilarity\n",
    "        #Numerical feature use euclidean distance\n",
    "        if self.type==float: \n",
    "            return (self.vals - cntr)**2\n",
    "        else:\n",
    "            #Get Weight of points, from WHICH paper?\n",
    "            weights = (self.valFreq + self.valDict[cntr])/(self.valFreq * self.valDict[cntr])\n",
    "        #2007 dissimilarity\n",
    "        if cntrdMask is not None:\n",
    "            return weights * (1-(self.vals==cntr).astype(int) *((self.vals[cntrdMask] == cntr).sum()/cntrdMask.sum()))\n",
    "        #Classic dissimilarity\n",
    "        else:\n",
    "            return weights * (self.vals!=cntr).astype(int)  \n",
    "            \n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "def initCentroids(features, sizes):\n",
    "#Init centroids based on Cao Paper\n",
    "    #Empty list of centroids\n",
    "    cntrds = [0 for i in range(sizes['clstrs'])]\n",
    "    #Density of each point\n",
    "    dens = np.zeros(sizes['pts'])\n",
    "    #Iterate through features\n",
    "    for feat in features:\n",
    "        #Update point density\n",
    "        dens += (feat.valFreq/(sizes['pts']*sizes['clstrs']))\n",
    "    cntrds[0] = [feat.vals[dens[0].argmax()] for feat in features]\n",
    "    #Iterate though remaining centroids, adapted from github implementation \n",
    "    for ki in range(1, sizes['clstrs']):\n",
    "        dens2 = np.zeros((ki, sizes['pts']))\n",
    "        #Iterate through already created centroids\n",
    "        for kii in range(ki):\n",
    "            #Similarity btwn cntrds and pts\n",
    "            sims = np.zeros((sizes['pts'], sizes['ftrs']))\n",
    "            #Iterate through features\n",
    "            for f, feat in enumerate(features):\n",
    "                sims[:,f] = feat.getSimilarity(cntrds[kii][f])\n",
    "            #Densities * similarites\n",
    "            dens2[kii] = dens * sims.sum(axis=1)\n",
    "        #New centroid has max dens*sims from previous centroids\n",
    "        cntrds[ki] = [feat.vals[np.argmax(np.min(dens2, axis=0))] for feat in features] \n",
    "    #Assign intial membship\n",
    "    cntrds, membship, cost = assignMembship(cntrds, features, sizes)\n",
    "    return cntrds, membship, cost\n",
    "\n",
    "def assignMembship(cntrds, features, sizes, membship=None, pred=False):\n",
    "#Assign membship to centroids, membship=True if dissim is 2007, pred=True for KModes predict\n",
    "    sims = np.zeros((sizes['pts'], sizes['clstrs']))\n",
    "    #Iterate through centroids\n",
    "    for i, cntrd in enumerate(cntrds):\n",
    "        #Get num and cat feat sims  \n",
    "        num_feats = np.zeros((sizes['pts'], sizes['n_ftrs']))\n",
    "        cat_feats = np.zeros((sizes['pts'], sizes['c_ftrs']))\n",
    "        n, c = 0, 0\n",
    "        #Iterate thorugh features\n",
    "        for f, feat in enumerate(features):\n",
    "            #Num features\n",
    "            if isinstance(feat.type, (float, int)):\n",
    "                num_feats[:,n] += feat.getSimilarity(cntrd[f])\n",
    "                n += 1\n",
    "            #Cat geatures\n",
    "            else:\n",
    "                #Choose which dissim to use\n",
    "                if membship is not None:\n",
    "                    #2007 dissim\n",
    "                    cntrdMask = (membship == i)\n",
    "                    cat_feats[:,c] += feat.getSimilarity(cntrd[f], cntrdMask)\n",
    "                else:\n",
    "                    #Orig disim\n",
    "                    cat_feats[:,c] += feat.getSimilarity(cntrd[f])\n",
    "                c += 1\n",
    "        #Sims of given centroid\n",
    "        sims[:,i] = num_feats.sum(axis=1) + sizes['gamma'] * cat_feats.sum(axis=1)\n",
    "    #Choose smallest dissim for each pt\n",
    "    membship = sims.argmin(axis=1)\n",
    "    #Cost is sum of smallest dissim\n",
    "    cost = sims.min(axis=1).sum()\n",
    "    #If centroid has no assigned pts\n",
    "    if (np.unique(membship).shape[0] != sizes['clstrs'])&(pred):\n",
    "        cntrds = newCentroids(cntrds, features, membship, sizes)\n",
    "        #Recursively assign membship\n",
    "        assignMemship(cntrds, features, sizes, membship)\n",
    "    return cntrds, membship, cost\n",
    "\n",
    "def newCentroids(cntrds, features, membship, sizes):\n",
    "#Create new centroids if centroid is not present in membship\n",
    "    #Missing centroids\n",
    "    missing = np.setdiff1d(range(0,sizes['clstrs']), membship)\n",
    "    #Largest centroid\n",
    "    max_cntrd = mode2(membship, val=False)\n",
    "    #Choose pts from largest centroid\n",
    "    new_cntrds = np.random.choice(np.where(membship == max_cntrd)[0], missing.shape[0])\n",
    "    #Replace old centroids with new points\n",
    "    for m, nc in zip(missing, new_cntrds):\n",
    "        cntrds[m] = [feat.vals[new_cntrds[nc]] for feat in features]\n",
    "    return cntrds\n",
    "\n",
    "def setCentroids(features, membship, sizes, dissim):\n",
    "#Set centroids from center of each feature\n",
    "    cntrds = [0 for c in range(sizes['clstrs'])]\n",
    "    #Iterate through centroids, get approp center for each feature\n",
    "    for i in range(sizes['clstrs']):\n",
    "        cntrds[i] = [feat.getCenter(membship==i) for feat in features]\n",
    "    #2007 dissim, pass membship\n",
    "    if dissim:\n",
    "        cntrds, membship, cost = assignMembship(cntrds, features, sizes, membship)\n",
    "    #Classsic dissim\n",
    "    else:\n",
    "        cntrds, membship, cost = assignMembship(cntrds, features, sizes)\n",
    "    return cntrds, membship, cost\n",
    " \n",
    "def setMembshipToLabels(membship, sizes):\n",
    "#Convert membship to 2D array\n",
    "    labels = np.zeros((sizes['pts'], sizes['clstrs']))\n",
    "    for r, cls, in enumerate(membship):\n",
    "        labels[r, cls] += 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "class KModes(BaseEstimator, ClusterMixin):\n",
    "#Implementation of KModes, with help from github implementation\n",
    "    def __init__(self, n_clusters=5, max_iter=100, gamma=1, dissim=False):\n",
    "        #Keep all size information in dictionary\n",
    "        self.sizes = {}\n",
    "        self.sizes['clstrs'], self.sizes['max_itr'] = n_clusters, max_iter\n",
    "        self.sizes['gamma'] = 1\n",
    "        #2007 dissim or classic dissim\n",
    "        self.dissim = dissim\n",
    "        return     \n",
    "    \n",
    "    def fit(self, X):\n",
    "    #Fit KModes to data\n",
    "        #Convert Pandas to np array\n",
    "        if 'pandas' in str(X.__class__):\n",
    "            X = X.values\n",
    "        \n",
    "        self.sizes['pts'], self.sizes['ftrs'] = X.shape\n",
    "        #Too few clusters\n",
    "        assert self.sizes['clstrs'] <= self.sizes['pts']\n",
    "        #Features to better form\n",
    "        self.features = np.array([Feature(col.dtype, col) for col in X.T])\n",
    "        #Save n_ftrs and c_ftrs\n",
    "        self.sizes['n_ftrs'] = int(np.sum([1 for feat in self.features if isinstance(feat.type, (float, int))]))\n",
    "        self.sizes['c_ftrs'] = int(self.sizes['ftrs'] - self.sizes['n_ftrs'])\n",
    "        \n",
    "        #Init centroids, membship and cost\n",
    "        cntrds, membship, cost = initCentroids(self.features, self.sizes)\n",
    "        \n",
    "        #Iterate until convergence or max iteration reached\n",
    "        itr, converged = 0, False\n",
    "        while itr <= self.sizes['max_itr'] and not converged:\n",
    "            itr += 1\n",
    "            #Set centroids, membship\n",
    "            cntrds, new_membship, new_cost = setCentroids(self.features, membship, self.sizes, self.dissim)\n",
    "            #Check if any pts changed membship\n",
    "            chngs = np.setdiff1d(new_membship, membship)\n",
    "            #Convergence conditions\n",
    "            converged = (chngs.shape[0] == 0) or (ncost >= cost)\n",
    "            membship, cost = new_membship, new_cost\n",
    "        \n",
    "        #Save fit info\n",
    "        self.membship_ = membship\n",
    "        self.labels_ = setMembshipToLabels(membship, self.sizes)\n",
    "        self.centroids_, self.cost_, self.itr_ = cntrds, cost, itr\n",
    "        return self   \n",
    "    \n",
    "    def predict(self, X):\n",
    "    #Given new data, assignMembship to centroids\n",
    "        assert hasattr(self, 'centroids_'), \"Model not yet fit\"\n",
    "        if 'pandas' in str(X.__class__):\n",
    "            X = X.values\n",
    "        new_features = np.array([Feature(col.dtype, col) for col in X.T])\n",
    "        new_sizes = sizes.copy()\n",
    "        new_sizes[pts] = X.shape[0]\n",
    "        cntrds, membship, cost = assignMembship(self.centroids_, new_features, new_sizes, pred=False)\n",
    "        new_labels = setMembshipToLabels(membship, sizes)\n",
    "        return(new_labels, cost)\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        return self.fit(X).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soybean = pd.read_csv('data/soybean.csv', header=None)\n",
    "x = soybean.drop(35, axis=1)\n",
    "x = x.astype(object)\n",
    "soyClusters = KModes(n_clusters=4, max_iter=1000, dissim=False).fit(soybean)\n",
    "soybean['Prediction'] = soyClusters.membship_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.192613960358905"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soyClusters.cost_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
