{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def standardize(labels):\n",
    "#Standardize numerical feature\n",
    "    return (labels-labels.mean())/labels.std(ddof=0)\n",
    "\n",
    "def cat_encode(labels):\n",
    "    ids, new_labels = np.unique(labels, return_inverse=True)\n",
    "    return new_labels, ids\n",
    "    \n",
    "def mode2(a, axis=0, val=False):\n",
    "#Return mode or mode freq of an array\n",
    "#code based on scipy.stats.mode\n",
    "    scores = np.unique(np.ravel(a))      \n",
    "    testshape = list(a.shape)\n",
    "    testshape[axis] = 1\n",
    "    oldmostfreq = np.zeros(testshape, dtype=a.dtype)\n",
    "    oldcounts = np.zeros(testshape, dtype=int)\n",
    "\n",
    "    for score in scores:\n",
    "        template = (a == score)\n",
    "        counts = np.expand_dims(np.sum(template, axis),axis)\n",
    "        mostfrequent = np.where(counts > oldcounts, score, oldmostfreq)\n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "        oldmostfreq = mostfrequent\n",
    "    \n",
    "    return oldcounts[0] if val else mostfrequent[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('data/3nja-bsch.tsv', sep='\\t')\n",
    "a = a.round(1)\n",
    "#a2 = a.dropna().copy()\n",
    "a2 = a.copy()\n",
    "for col in a2:\n",
    "    typ = str(a2[col].dtype)\n",
    "    if typ in ['int', 'int32', 'int64','float', 'float32', 'float64']:\n",
    "        a2[col] = standardize(a2[col])\n",
    "   \n",
    "\n",
    "a3 = a2.copy().dropna()\n",
    "a3.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('data/h3zm-ta5h.tsv', sep='\\t')\n",
    "b = b.round(1)\n",
    "b2 = b.copy()\n",
    "bCodes = []\n",
    "for col in b2:\n",
    "    typ = str(b2[col].dtype)\n",
    "    if typ in ['int', 'int32', 'int64','float', 'float32', 'float64']:\n",
    "        b2[col] = standardize(b2[col])\n",
    "    elif typ in ['object', 'string']:\n",
    "        b2[col], fcodes = cat_encode(b2[col])\n",
    "        bCodes.append(fcodes)\n",
    "        \n",
    "b3 = b2.dropna().copy()\n",
    "b3.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "#Feature subclass for better use with KModes\n",
    "    def __init__(self, featType, labels):\n",
    "        #values in array form and feature dtype\n",
    "        #self.vals = labels[~pd.isnull(labels)]\n",
    "        #self.missing = np.where(pd.isnull(labels))[0]\n",
    "        self.vals = labels\n",
    "        self.size = self.vals.shape[0]\n",
    "        self.type = featType\n",
    "        #unique values, their orig indices and counts\n",
    "        vals, inds, counts = np.unique(self.vals, return_inverse=True, return_counts=True)\n",
    "        #Feature dictionary for use in itialization\n",
    "        self.valDict = {v:c for v,c in  zip(vals, counts)}\n",
    "        #frequency of values in orig indices\n",
    "        self.valFreq = counts[inds]\n",
    "        #self.valFreqMiss = np.insert(counts[inds], self.missing, 0)\n",
    "        return\n",
    "    \n",
    "    def getCenter(self, cMsk):\n",
    "    #Get center of feature in given centroid\n",
    "        #Mean for num features\n",
    "        #msk = cMsk[np.setdiff1d(np.arange(cMsk.shape[0]), self.missing)]\n",
    "        msk = cMsk\n",
    "        if self.type==float:\n",
    "            return self.vals[msk].mean()\n",
    "        #Mode for cat features\n",
    "        else:\n",
    "            return mode2(self.vals[msk], val=False)        \n",
    "    \n",
    "    def getDissimilarity(self, cntr, cMsk=None):\n",
    "    #Given centroid center, get dissimilarity\n",
    "        #Numerical feature use euclidean distance\n",
    "        if self.type==float: \n",
    "            dissims = (self.vals - cntr)**2\n",
    "        else:\n",
    "            #Get Weight of points, from WHICH paper?\n",
    "            weights = (self.valFreq + self.valDict[cntr])/(self.valFreq * self.valDict[cntr])\n",
    "            #2007 dissimilarity\n",
    "            if cMsk is not None:\n",
    "                msk = cMsk\n",
    "                #msk = cMsk[np.setdiff1d(np.arange(cMsk.shape[0]), self.missing)]\n",
    "                dissims = weights * (1-(self.vals==cntr).astype(int) *((self.vals[msk] == cntr).sum()/msk.sum()))\n",
    "            #Classic dissimilarity\n",
    "            else:\n",
    "                dissims = weights * (self.vals != cntr).astype(int)\n",
    "        \n",
    "        return dissims\n",
    "        #dissims2 = np.insert(dissims, self.missing, 1000).astype(float)\n",
    "        #return dissims2\n",
    "        \n",
    "    def calcEntropy(self, cMsk):\n",
    "        msk = cMsk\n",
    "        #msk = cMsk[np.setdiff1d(np.arange(cMsk.shape[0]), self.missing)]\n",
    "        local_vals = self.vals[msk]\n",
    "        if local_vals.shape[0] == 1: return 0\n",
    "        \n",
    "        keys, counts_raw = np.unique(local_vals, return_counts=True)        \n",
    "        counts = counts_raw[counts_raw.nonzero()]\n",
    "        probs = counts/counts.sum() \n",
    "\n",
    "        label_entropy = -np.sum(probs * np.log(probs)) \n",
    "        entropy_weight = 2*(1 - 1/(1 + np.exp(-label_entropy)))\n",
    "        return entropy_weight * label_entropy\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "def initIndivCentroid(features, info, cntrd_id):\n",
    "    cntrd_tmp = [0 for i in range(info['n_ftrs'])]\n",
    "\n",
    "    for f, feat in enumerate(features):\n",
    "        f_id = cntrd_id - np.sum(feat.missing < cntrd_id)\n",
    "        if f_id in feat.missing:\n",
    "            cntrd_tmp[f] = feat.getCenter(np.ones(feat.size, dtype=bool))\n",
    "        else:\n",
    "            cntrd_tmp[f] = feat.vals[f]\n",
    "\n",
    "    return cntrd_tmp\n",
    "\n",
    "def initCentroids(features, info):\n",
    "#Init centroids based on Cao Paper\n",
    "    #Empty list of centroids\n",
    "    cntrds = [0 for i in range(info['n_clstrs'])]\n",
    "    #Density of each point\n",
    "    dens = np.zeros(info['n_rows'])\n",
    "    #Iterate through features\n",
    "    for feat in features:\n",
    "        #Update point density\n",
    "        dens += (feat.valFreq/(info['n_rows']*info['n_clstrs']))\n",
    "    cntrds[0] = [feat.vals[dens.argmax()] for feat in features]\n",
    "    #Iterate though remaining centroids, adapted from github implementation \n",
    "    for ki in range(1, info['n_clstrs']):\n",
    "        adj_dens = np.zeros((ki, info['n_rows']))\n",
    "        #Iterate through already created centroids\n",
    "        for kii in range(0,ki):\n",
    "            #Similarity btwn cntrds and pts\n",
    "            dissims = np.zeros((info['n_rows'], info['n_ftrs']))\n",
    "            #dissims = np.zeros(info['n_rows'])\n",
    "            #Iterate through features\n",
    "            for f, feat in enumerate(features):\n",
    "                dissims[:,f] += feat.getDissimilarity(cntrds[kii][f]).astype(float)\n",
    "            #Densities * similarites\n",
    "            adj_dens[kii] = dens * dissims.sum(axis=1)\n",
    "        #New centroid has max dens*sims from previous centroids\n",
    "        cntrds[ki] = [feat.vals[np.argmax(np.min(adj_dens, axis=0))] for feat in features]\n",
    "    #Assign intial membship\n",
    "    cntrds, membship, cost = assignMembship(cntrds, features, info)\n",
    "    return cntrds, membship, cost\n",
    "\n",
    "def assignMembship(cntrds, features, info, membship=None, pred=True):\n",
    "#Assign membship to centroids, membship=True if dissim is 2007, pred=True for KModes predict\n",
    "    dissims = np.zeros((info['n_rows'], info['n_clstrs']))\n",
    "    #Iterate through centroids\n",
    "    for i, cntrd in enumerate(cntrds):\n",
    "        #Get num and cat feat sims  \n",
    "        num_feats = np.zeros((info['n_rows'], info['num']))\n",
    "        cat_feats = np.zeros((info['n_rows'], info['cat']))\n",
    "        n, c = 0, 0\n",
    "        #Iterate thorugh features\n",
    "        for f, feat in enumerate(features):\n",
    "            #Num features\n",
    "            if isinstance(feat.type, (float, int)):\n",
    "                num_feats[:,n] += feat.getDissimilarity(cntrd[f]).astype(float)\n",
    "                n += 1\n",
    "            #Cat geatures\n",
    "            else:\n",
    "                #Choose which dissim to use\n",
    "                if membship is not None:\n",
    "                    #2007 dissim\n",
    "                    cntrdMask = (membship == i)\n",
    "                    cat_feats[:,c] += feat.getDissimilarity(cntrd[f], cntrdMask).astype(float)\n",
    "                else:\n",
    "                    #Orig disim\n",
    "                    cat_feats[:,c] += feat.getDissimilarity(cntrd[f]).astype(float)\n",
    "                c += 1\n",
    "        #Sims of given centroid\n",
    "        dissims[:,i] = num_feats.sum(axis=1) + info['gamma'] * cat_feats.sum(axis=1)\n",
    "    print(dissims)\n",
    "    #Choose smallest dissim for each pt\n",
    "    membship = dissims.argmin(axis=1)\n",
    "    #Cost is sum of smallest dissim\n",
    "    cost = dissims.min(axis=1).sum()\n",
    "    #If centroid has no assigned pts\n",
    "    if (np.unique(membship).shape[0] != info['n_clstrs'])&(not pred):\n",
    "        print('meep meep')\n",
    "        cntrds = newCentroids(cntrds, features, membship, info)\n",
    "        #Recursively assign membship\n",
    "        cntrds, membship, cost = assignMemship(cntrds, features, info, membship)\n",
    "    return cntrds, membship, cost\n",
    "\n",
    "def newCentroids(cntrds, features, membship, info):\n",
    "#Create new centroids if centroid is not present in membship\n",
    "    #Missing centroids\n",
    "    missing = np.setdiff1d(range(0,info['n_clstrs']), membship)\n",
    "    #Largest centroid\n",
    "    max_cntrd = mode2(membship, val=False)\n",
    "    #Choose pts from largest centroid\n",
    "    new_cntrds = np.random.choice(np.where(membship == max_cntrd)[0], missing.shape[0])\n",
    "    #Replace old centroids with new points\n",
    "    for m, nc in zip(missing, new_cntrds):\n",
    "        cntrds[m] = [feat.vals[new_cntrds[nc]] for feat in features]\n",
    "    return cntrds\n",
    "\n",
    "def setCentroids(features, membship, info, dissim):\n",
    "#Set centroids from center of each feature\n",
    "    cntrds = [0 for c in range(info['n_clstrs'])]\n",
    "    #Iterate through centroids, get approp center for each feature\n",
    "    for i in range(info['n_clstrs']):\n",
    "        cntrds[i] = [feat.getCenter(membship==i) for feat in features]\n",
    "    #2007 dissim, pass membship\n",
    "    if dissim:\n",
    "        cntrds, membship, cost = assignMembship(cntrds, features, info, membship)\n",
    "    #Classsic dissim\n",
    "    else:\n",
    "        cntrds, membship, cost = assignMembship(cntrds, features, info)\n",
    "    return cntrds, membship, cost\n",
    " \n",
    "def setMembshipToMatrix(membship, info):\n",
    "#Convert membship to 2D array\n",
    "    labels = np.zeros((info['n_rows'], info['n_clstrs']))\n",
    "    for r, cls, in enumerate(membship):\n",
    "        labels[r, cls] += 1\n",
    "    return labels\n",
    "\n",
    "def doGWE(features, msk):\n",
    "    assigned = np.where(msk)[0]\n",
    "    tot_e = np.sum([feat.calcEntropy(msk) for feat in features]) #calc initial weighted-entropy\n",
    "    o_factors = np.array([tot_e for x in range(assigned.shape[0])])\n",
    "    for o, i in enumerate(assigned):\n",
    "        msk[i] = False\n",
    "        wo = np.sum([feat.calcEntropy(msk) for feat in features])\n",
    "        o_factors[o]  -= wo if wo != 0 else (tot_e + 1)\n",
    "        msk[i] = True\n",
    "    msk_msk = (o_factors > 0) \n",
    "    pts = np.zeros(msk.shape[0], dtype=bool)\n",
    "    pts[assigned] = msk_msk\n",
    "    return np.arange(msk.shape[0])[pts]\n",
    "\n",
    "def getOutliers(features, membship, info):\n",
    "    outliersList =  [0 for i in range(info['n_clstrs'])]\n",
    "    \n",
    "    for i in range(info['n_clstrs']):\n",
    "        outliersList[i] = doGWE(features, membship == i)\n",
    "        \n",
    "    return np.array(list(itertools.chain.from_iterable(outliersList)))   \n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "class KModes(BaseEstimator, ClusterMixin):\n",
    "#Implementation of KModes, with help from github implementation\n",
    "    def __init__(self, n_clusters=5, max_iter=100, gamma=1, dissim=False):\n",
    "        #Keep all size information in dictionary\n",
    "        self.info = {}\n",
    "        self.info['n_clstrs'], self.info['max_itr'] = n_clusters, max_iter\n",
    "        self.info['gamma'] = 1\n",
    "        #2007 dissim or classic dissim\n",
    "        self.dissim = dissim\n",
    "        return     \n",
    "    \n",
    "    def fit(self, X, types):\n",
    "    #Fit KModes to data\n",
    "        #Convert Pandas to np array\n",
    "        if 'pandas' in str(X.__class__):\n",
    "            X = X.values\n",
    "        \n",
    "        self.info['n_rows'], self.info['n_ftrs'] = X.shape\n",
    "        #Too few clusters\n",
    "        assert self.info['n_clstrs'] <= self.info['n_rows']\n",
    "        #Features to better form\n",
    "        self.features = np.array([Feature(types[i], X[:,i]) for i in range(X.shape[1])])\n",
    "        #Save n_ftrs and c_ftrs\n",
    "        self.info['num'] = int(np.sum([1 for feat in self.features if isinstance(feat.type, (float, int))]))\n",
    "        self.info['cat'] = int(self.info['n_ftrs'] - self.info['num'])\n",
    "        \n",
    "        #Init centroids, membship and cost\n",
    "        cntrds, membship, cost = initCentroids(self.features, self.info)\n",
    "    \n",
    "        #Iterate until convergence or max iteration reached\n",
    "        itr, converged = 0, False\n",
    "        while (itr <= self.info['max_itr'])&(not converged):\n",
    "            itr += 1\n",
    "            #Set centroids, membship\n",
    "            cntrds, new_membship, new_cost = setCentroids(self.features, membship, self.info, self.dissim)\n",
    "            #Check if any pts changed membship\n",
    "            chngs = np.sum(new_membship != membship)\n",
    "            #Convergence conditions\n",
    "            converged = (chngs == 0)|(new_cost >= cost)\n",
    "            membship, cost = new_membship, new_cost\n",
    "        \n",
    "        #Save fit info\n",
    "        self.outliers_ = getOutliers(self.features, membship, self.info)\n",
    "        self.membship_ = membship\n",
    "        self.matrix_ = setMembshipToMatrix(membship, self.info)\n",
    "        self.centroids_, self.cost_, self.itr_ = cntrds, cost, itr\n",
    "        return self   \n",
    "    \n",
    "    def predict(self, X):\n",
    "    #Given new data, assignMembship to centroids\n",
    "        assert hasattr(self, 'centroids_'), \"Model not yet fit\"\n",
    "        if 'pandas' in str(X.__class__):\n",
    "            X = X.values\n",
    "        new_features = np.array([Feature(col.dtype, col) for col in X.T])\n",
    "        new_info = self.info.copy()\n",
    "        new_info[pts] = X.shape[0]\n",
    "        cntrds, membship, cost = assignMembship(self.centroids_, new_features, new_info, pred=True)\n",
    "        new_labels = setMembshipToLabels(membship, info)\n",
    "        return new_labels, cost\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        return self.fit(X).predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "8\n",
      "38\n",
      "[[  2.48842272 151.32468178  13.86657714 121.4746843 ]\n",
      " [  2.70333214 147.80107104  13.02143565 118.61745511]\n",
      " [  2.17685113 157.95578496  14.20836242 127.74155123]\n",
      " [  2.18053985 157.71079566  13.75834073 128.10302394]\n",
      " [  2.93269639 148.98953356  13.69633983 120.52640544]\n",
      " [  2.56625261 151.01197772  13.98325342 120.76364646]\n",
      " [  2.58059224 150.28887025  13.02184666 121.18617171]\n",
      " [  2.85887613 146.75468937  13.81631583 117.50808908]\n",
      " [ 14.96054916 122.52854124   0.         116.32765816]\n",
      " [  2.59990748 149.10704952  11.59375142 121.64207088]\n",
      " [  2.34333135 154.66303416  13.58157694 125.23181979]\n",
      " [  3.01047317 146.64871533  14.02548975 117.71046557]\n",
      " [  2.0469968  163.18101235  14.36878539 132.90735374]\n",
      " [  2.77680228 148.66644992  13.74549989 118.75387421]\n",
      " [  2.64781468 149.22820375  14.05840029 119.43407077]\n",
      " [  2.63912435 150.47261583  14.17564919 120.46451022]\n",
      " [  0.         167.35981965  14.96054916 136.7165307 ]\n",
      " [  2.33178926 154.15738982  13.79456136 124.35916018]\n",
      " [  2.39317707 153.9160152   13.08258898 124.79368828]\n",
      " [167.35981965   0.         122.52854124  14.25011724]\n",
      " [  3.18134046 152.03360341  14.73608078 121.25054639]\n",
      " [  2.52404908 153.3851924   14.05823702 122.92949793]\n",
      " [  3.04263265 147.20725722  13.67317868 117.21257527]\n",
      " [  2.40358935 154.81324572  12.25181248 126.37939663]\n",
      " [  2.15615271 163.61691253  14.88665595 132.61192707]\n",
      " [  2.393504   155.72924576  13.70405137 125.55567039]\n",
      " [  2.60124088 156.33083946  14.71090747 125.02550253]\n",
      " [  2.70114476 151.79913774  14.27782348 122.07889206]\n",
      " [  2.7579776  151.20814484  14.32155451 121.47289684]\n",
      " [  2.77743626 150.23313864  12.96710203 120.93108164]\n",
      " [  2.76190176 151.43649192  14.5021565  120.92737749]\n",
      " [  2.9170928  147.86526118  14.03738591 118.28065207]\n",
      " [  2.74418482 152.10903191  14.1854102  121.66364871]\n",
      " [  2.41411208 157.89966191  14.53378631 126.6216748 ]\n",
      " [  2.66444672 152.812608    14.47569869 122.15520212]\n",
      " [  2.58252702 153.40613397  13.73927188 123.75298063]\n",
      " [  4.24553706 134.25713704  10.87087255 107.99160442]\n",
      " [  2.41144637 154.10263037  13.34847203 124.56382524]\n",
      " [136.7165307   14.25011724 116.32765816   0.        ]\n",
      " [  2.55007023 168.00684108  15.51412988 137.25383338]\n",
      " [  1.88340357 166.67350775  14.84746321 135.92050005]]\n",
      "[[2.03480346e+00 1.51324682e+02 1.38665771e+01 1.21474684e+02]\n",
      " [2.09737154e+00 1.47801071e+02 1.30214357e+01 1.18617455e+02]\n",
      " [5.93782205e-02 1.57955785e+02 1.42083624e+01 1.27741551e+02]\n",
      " [2.07944414e+00 1.57710796e+02 1.37583407e+01 1.28103024e+02]\n",
      " [2.39379166e+00 1.48989534e+02 1.36963398e+01 1.20526405e+02]\n",
      " [2.07887665e+00 1.51011978e+02 1.39832534e+01 1.20763646e+02]\n",
      " [2.10972516e+00 1.50288870e+02 1.30218467e+01 1.21186172e+02]\n",
      " [2.17795154e+00 1.46754689e+02 1.38163158e+01 1.17508089e+02]\n",
      " [1.35964683e+01 1.22528541e+02 0.00000000e+00 1.16327658e+02]\n",
      " [2.14812306e+00 1.49107050e+02 1.15937514e+01 1.21642071e+02]\n",
      " [2.08624424e+00 1.54663034e+02 1.35815769e+01 1.25231820e+02]\n",
      " [2.32444555e+00 1.46648715e+02 1.40254898e+01 1.17710466e+02]\n",
      " [2.20036102e+00 1.63181012e+02 1.43687854e+01 1.32907354e+02]\n",
      " [2.17685681e+00 1.48666450e+02 1.37454999e+01 1.18753874e+02]\n",
      " [2.07981061e+00 1.49228204e+02 1.40584003e+01 1.19434071e+02]\n",
      " [2.12524147e+00 1.50472616e+02 1.41756492e+01 1.20464510e+02]\n",
      " [2.34882075e+00 1.67359820e+02 1.49605492e+01 1.36716531e+02]\n",
      " [2.03340255e+00 1.54157390e+02 1.37945614e+01 1.24359160e+02]\n",
      " [2.11729713e+00 1.53916015e+02 1.30825890e+01 1.24793688e+02]\n",
      " [1.53028811e+02 0.00000000e+00 1.22528541e+02 1.42501172e+01]\n",
      " [2.70317057e+00 1.52033603e+02 1.47360808e+01 1.21250546e+02]\n",
      " [2.16011505e+00 1.53385192e+02 1.40582370e+01 1.22929498e+02]\n",
      " [2.36710790e+00 1.47207257e+02 1.36731787e+01 1.17212575e+02]\n",
      " [2.21904138e+00 1.54813246e+02 1.22518125e+01 1.26379397e+02]\n",
      " [2.30330409e+00 1.63616913e+02 1.48866559e+01 1.32611927e+02]\n",
      " [2.17283590e+00 1.55729246e+02 1.37040514e+01 1.25555670e+02]\n",
      " [2.34997597e+00 1.56330839e+02 1.47109075e+01 1.25025503e+02]\n",
      " [2.26965617e+00 1.51799138e+02 1.42778235e+01 1.22078892e+02]\n",
      " [2.29237198e+00 1.51208145e+02 1.43215545e+01 1.21472897e+02]\n",
      " [2.29995120e+00 1.50233139e+02 1.29671020e+01 1.20931082e+02]\n",
      " [2.27790461e+00 1.51436492e+02 1.45021565e+01 1.20927377e+02]\n",
      " [2.28422744e+00 1.47865261e+02 1.40373859e+01 1.18280652e+02]\n",
      " [2.30432197e+00 1.52109032e+02 1.41854102e+01 1.21663649e+02]\n",
      " [2.25635015e+00 1.57899662e+02 1.45337863e+01 1.26621675e+02]\n",
      " [2.25079918e+00 1.52812608e+02 1.44756987e+01 1.22155202e+02]\n",
      " [2.24861679e+00 1.53406134e+02 1.37392719e+01 1.23752981e+02]\n",
      " [3.03120785e+00 1.34257137e+02 1.08708726e+01 1.07991604e+02]\n",
      " [2.13232680e+00 1.54102630e+02 1.33484720e+01 1.24563825e+02]\n",
      " [1.23351044e+02 1.42501172e+01 1.16327658e+02 0.00000000e+00]\n",
      " [2.90350877e+00 1.68006841e+02 1.55141299e+01 1.37253833e+02]\n",
      " [2.23684210e+00 1.66673508e+02 1.48474632e+01 1.35920500e+02]]\n"
     ]
    }
   ],
   "source": [
    "a_types = [str, float, float, float, float, float, float, str, str, float, float, float, float, float, float, float, float, float, float, float, float, float]\n",
    "ninjaClusters = KModes(n_clusters=int(np.sqrt(a3.shape[0]/2))).fit(a3, a_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_types = [float, str, float, float, str, float, float, float, float, float, float, float, float, str, float, float]\n",
    "h3zmClusters = KModes(n_clusters=int(np.sqrt(b2.shape[0]/2))).fit(b2, b_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 40])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninjaClusters.outliers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([152, 166, 248, 262, 264, 346, 444, 458, 183, 185, 191, 485, 187,\n",
       "        72,  74, 154, 464, 466, 104, 202, 300, 398])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3zmClusters.outliers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "#Feature subclass for better use with KModes\n",
    "    def __init__(self, featType, labels):\n",
    "        #values in array form and feature dtype\n",
    "        self.vals = labels[~pd.isnull(labels)]\n",
    "        self.missing = np.where(pd.isnull(labels))[0]\n",
    "        self.size = self.vals.shape[0]\n",
    "        self.type = featType\n",
    "        #unique values, their orig indices and counts\n",
    "        vals, inds, counts = np.unique(self.vals, return_inverse=True, return_counts=True)\n",
    "        #Feature dictionary for use in itialization\n",
    "        self.valDict = {v:c for v,c in  zip(vals, counts)}\n",
    "        #frequency of values in orig indices\n",
    "        self.valFreq = counts[inds]\n",
    "        self.valFreqMiss = self.fillMissing(self.valFreq)\n",
    "        return\n",
    "    \n",
    "    def fillMissing(self, arr, high=False):\n",
    "        for miss in self.missing:\n",
    "            if high:\n",
    "                arr = np.concatenate((arr[:miss], [np.nan], arr[miss:]))\n",
    "            else:\n",
    "                arr = np.concatenate((arr[:miss], [np.nan], arr[miss:]))\n",
    "        return arr\n",
    "    \n",
    "    def getCenter(self, cMsk):\n",
    "    #Get center of feature in given centroid\n",
    "        #Mean for num features\n",
    "        msk = cMsk[np.setdiff1d(np.arange(cMsk.shape[0]), self.missing)]\n",
    "        if self.type==float:\n",
    "            return self.vals[msk].mean()\n",
    "        #Mode for cat features\n",
    "        else:\n",
    "            return mode2(self.vals[msk], val=False)        \n",
    "    \n",
    "    def getDissimilarity(self, cntr, high=False, cMsk=None):\n",
    "    #Given centroid center, get dissimilarity\n",
    "        #Numerical feature use euclidean distance\n",
    "        if self.type==float: \n",
    "            dissims = (self.vals - cntr)**2\n",
    "        else:\n",
    "            #Get Weight of points, from WHICH paper?\n",
    "            weights = (self.valFreq + self.valDict[cntr])/(self.valFreq * self.valDict[cntr])\n",
    "            #2007 dissimilarity\n",
    "            if cMsk is not None:\n",
    "                msk = cMsk[np.setdiff1d(np.arange(cMsk.shape[0]), self.missing)]\n",
    "                dissims = weights * (1-(self.vals==cntr).astype(int) *((self.vals[msk] == cntr).sum()/msk.sum()))\n",
    "            #Classic dissimilarity\n",
    "            else:\n",
    "                dissims = weights * (self.vals != cntr).astype(int)\n",
    "                \n",
    "        dissims = self.fillMissing(dissims, high).astype(np.float64)\n",
    "        return dissims\n",
    "                \n",
    "    def calcEntropy(self, cMsk):\n",
    "        msk = cMsk[np.setdiff1d(np.arange(cMsk.shape[0]), self.missing)]\n",
    "        local_vals = self.vals[msk]\n",
    "        if local_vals.shape[0] == 1: return 0\n",
    "        \n",
    "        keys, counts_raw = np.unique(local_vals, return_counts=True)        \n",
    "        counts = counts_raw[counts_raw.nonzero()]\n",
    "        probs = counts/counts.sum() \n",
    "\n",
    "        label_entropy = -np.sum(probs * np.log(probs)) \n",
    "        entropy_weight = 2*(1 - 1/(1 + np.exp(-label_entropy)))\n",
    "        return entropy_weight * label_entropy\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "def initCentroids(features, info):\n",
    "#Init centroids based on Cao Paper\n",
    "    #Empty list of centroids\n",
    "    cntrds = [0 for i in range(info['n_clstrs'])]\n",
    "    #Density of each point\n",
    "    dens = np.zeros(info['n_rows'])\n",
    "    #Iterate through features\n",
    "    for feat in features:\n",
    "        #Update point density\n",
    "        dens += (feat.valFreqMiss/(info['n_rows']*info['n_clstrs']))\n",
    "    #cntrds[0] = [feat.vals[dens.argmax()] for feat in features]\n",
    "    cntrds[0] = [feat.vals[np.nanargmax(dens)] for feat in features]\n",
    "    #Iterate though remaining centroids, adapted from github implementation \n",
    "    for ki in range(1, info['n_clstrs']):\n",
    "        adj_dens = np.zeros((ki, info['n_rows']))\n",
    "        #Iterate through already created centroids\n",
    "        for kii in range(0,ki):\n",
    "            #Similarity btwn cntrds and pts\n",
    "            dissims = np.zeros((info['n_rows'], info['n_ftrs']))\n",
    "            #dissims = np.zeros(info['n_rows'])\n",
    "            #Iterate through features\n",
    "            for f, feat in enumerate(features):\n",
    "                dissims[:,f] += feat.getDissimilarity(cntrds[kii][f], high=False)\n",
    "            #Densities * similarites\n",
    "            adj_dens[kii] = (dens * dissims.sum(axis=1)).astype(np.float64)\n",
    "        #New centroid has max dens*sims from previous centroids\n",
    "        cntrds[ki] = [feat.vals[np.nanargmax(np.nanmin(adj_dens.astype(np.float64), axis=0))] for feat in features]\n",
    "    #Assign intial membship\n",
    "    cntrds, membship, cost = assignMembship(cntrds, features, info)\n",
    "    return cntrds, membship, cost\n",
    "\n",
    "def assignMembship(cntrds, features, info, membship=None, pred=True):\n",
    "#Assign membship to centroids, membship=True if dissim is 2007, pred=True for KModes predict\n",
    "    dissims = np.zeros((info['n_rows'], info['n_clstrs']))\n",
    "    #Iterate through centroids\n",
    "    for i, cntrd in enumerate(cntrds):\n",
    "        #Get num and cat feat sims  \n",
    "        num_feats = np.zeros((info['n_rows'], info['num']))\n",
    "        cat_feats = np.zeros((info['n_rows'], info['cat']))\n",
    "        n, c = 0, 0\n",
    "        #Iterate thorugh features\n",
    "        for f, feat in enumerate(features):\n",
    "            #Num features\n",
    "            if isinstance(feat.type, (float, int)):\n",
    "                num_feats[:,n] += feat.getDissimilarity(cntrd[f], high=True)\n",
    "                n += 1\n",
    "            #Cat geatures\n",
    "            else:\n",
    "                #Choose which dissim to use\n",
    "                if membship is not None:\n",
    "                    #2007 dissim\n",
    "                    cntrdMask = (membship == i)\n",
    "                    cat_feats[:,c] += feat.getDissimilarity(cntrd[f], high=True, cMsk=cntrdMask)\n",
    "                else:\n",
    "                    #Orig disim\n",
    "                    cat_feats[:,c] += feat.getDissimilarity(cntrd[f], high=True)\n",
    "                c += 1\n",
    "        #Sims of given centroid\n",
    "        dissims[:,i] = np.nansum(num_feats, axis=1) + info['gamma'] * np.nansum(cat_feats, axis=1)\n",
    "    #Choose smallest dissim for each pt\n",
    "    membship = np.nanargmin(dissims, axis=1)\n",
    "    #Cost is sum of smallest dissim\n",
    "    cost = np.nanmin(dissims, axis=1).sum()\n",
    "    #If centroid has no assigned pts\n",
    "    if (np.unique(membship).shape[0] != info['n_clstrs'])&(not pred):\n",
    "        print('meep meep')\n",
    "        cntrds = newCentroids(cntrds, features, membship, info)\n",
    "        #Recursively assign membship\n",
    "        cntrds, membship, cost = assignMemship(cntrds, features, info, membship)\n",
    "    return cntrds, membship, cost\n",
    "\n",
    "def newCentroids(cntrds, features, membship, info):\n",
    "#Create new centroids if centroid is not present in membship\n",
    "    #Missing centroids\n",
    "    missing = np.setdiff1d(range(0,info['n_clstrs']), membship)\n",
    "    #Largest centroid\n",
    "    max_cntrd = mode2(membship, val=False)\n",
    "    #Choose pts from largest centroid\n",
    "    new_cntrds = np.random.choice(np.where(membship == max_cntrd)[0], missing.shape[0])\n",
    "    #Replace old centroids with new points\n",
    "    for m, nc in zip(missing, new_cntrds):\n",
    "        cntrds[m] = [feat.vals[new_cntrds[nc]] for feat in features]\n",
    "    return cntrds\n",
    "\n",
    "def setCentroids(features, membship, info, dissim):\n",
    "#Set centroids from center of each feature\n",
    "    cntrds = [0 for c in range(info['n_clstrs'])]\n",
    "    #Iterate through centroids, get approp center for each feature\n",
    "    for i in range(info['n_clstrs']):\n",
    "        cntrds[i] = [feat.getCenter(membship==i) for feat in features]\n",
    "    #2007 dissim, pass membship\n",
    "    if dissim:\n",
    "        cntrds, membship, cost = assignMembship(cntrds, features, info, membship)\n",
    "    #Classsic dissim\n",
    "    else:\n",
    "        cntrds, membship, cost = assignMembship(cntrds, features, info)\n",
    "    return cntrds, membship, cost\n",
    " \n",
    "def setMembshipToMatrix(membship, info):\n",
    "#Convert membship to 2D array\n",
    "    labels = np.zeros((info['n_rows'], info['n_clstrs']))\n",
    "    for r, cls, in enumerate(membship):\n",
    "        labels[r, cls] += 1\n",
    "    return labels\n",
    "\n",
    "def doGWE(features, msk):\n",
    "    assigned = np.where(msk)[0]\n",
    "    tot_e = np.sum([feat.calcEntropy(msk) for feat in features]) #calc initial weighted-entropy\n",
    "    o_factors = np.array([tot_e for x in range(assigned.shape[0])])\n",
    "    for o, i in enumerate(assigned):\n",
    "        msk[i] = False\n",
    "        wo = np.sum([feat.calcEntropy(msk) for feat in features])\n",
    "        o_factors[o]  -= wo if wo != 0 else (tot_e + 1)\n",
    "        msk[i] = True\n",
    "    msk_msk = (o_factors > 0) \n",
    "    pts = np.zeros(msk.shape[0], dtype=bool)\n",
    "    pts[assigned] = msk_msk\n",
    "    return np.arange(msk.shape[0])[pts]\n",
    "\n",
    "def getOutliers(features, membship, info):\n",
    "    outliersList =  [0 for i in range(info['n_clstrs'])]\n",
    "    \n",
    "    for i in range(info['n_clstrs']):\n",
    "        outliersList[i] = doGWE(features, membship == i)\n",
    "        \n",
    "    return np.array(list(itertools.chain.from_iterable(outliersList)))   \n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "class KModes(BaseEstimator, ClusterMixin):\n",
    "#Implementation of KModes, with help from github implementation\n",
    "    def __init__(self, n_clusters=5, max_iter=100, gamma=1, dissim=False):\n",
    "        #Keep all size information in dictionary\n",
    "        self.info = {}\n",
    "        self.info['n_clstrs'], self.info['max_itr'] = n_clusters, max_iter\n",
    "        self.info['gamma'] = 1\n",
    "        #2007 dissim or classic dissim\n",
    "        self.dissim = dissim\n",
    "        return     \n",
    "    \n",
    "    def fit(self, X, types):\n",
    "    #Fit KModes to data\n",
    "        #Convert Pandas to np array\n",
    "        if 'pandas' in str(X.__class__):\n",
    "            X = X.values\n",
    "        \n",
    "        self.info['n_rows'], self.info['n_ftrs'] = X.shape\n",
    "        #Too few clusters\n",
    "        assert self.info['n_clstrs'] <= self.info['n_rows']\n",
    "        #Features to better form\n",
    "        self.features = np.array([Feature(types[i], X[:,i]) for i in range(X.shape[1])])\n",
    "        #Save n_ftrs and c_ftrs\n",
    "        self.info['num'] = int(np.sum([1 for feat in self.features if isinstance(feat.type, (float, int))]))\n",
    "        self.info['cat'] = int(self.info['n_ftrs'] - self.info['num'])\n",
    "        \n",
    "        #Init centroids, membship and cost\n",
    "        cntrds, membship, cost = initCentroids(self.features, self.info)\n",
    "    \n",
    "        #Iterate until convergence or max iteration reached\n",
    "        itr, converged = 0, False\n",
    "        while (itr <= self.info['max_itr'])&(not converged):\n",
    "            itr += 1\n",
    "            #Set centroids, membship\n",
    "            cntrds, new_membship, new_cost = setCentroids(self.features, membship, self.info, self.dissim)\n",
    "            #Check if any pts changed membship\n",
    "            chngs = np.sum(new_membship != membship)\n",
    "            #Convergence conditions\n",
    "            converged = (chngs == 0)|(new_cost >= cost)\n",
    "            membship, cost = new_membship, new_cost\n",
    "        \n",
    "        #Save fit info\n",
    "        self.outliers_ = getOutliers(self.features, membship, self.info)\n",
    "        self.membship_ = membship\n",
    "        self.matrix_ = setMembshipToMatrix(membship, self.info)\n",
    "        self.centroids_, self.cost_, self.itr_ = cntrds, cost, itr\n",
    "        return self   \n",
    "    \n",
    "    def predict(self, X, types):\n",
    "    #Given new data, assignMembship to centroids\n",
    "        assert hasattr(self, 'centroids_'), \"Model not yet fit\"\n",
    "        if 'pandas' in str(X.__class__):\n",
    "            X = X.values\n",
    "        new_features = np.array([Feature(types[i], X[:,i]) for i in range(X.shape[1])])\n",
    "        new_info = self.info.copy()\n",
    "        new_info['n_rows'] = X.shape[0]\n",
    "        cntrds, membship, cost = assignMembship(self.centroids_, new_features, new_info, pred=True)\n",
    "        new_labels = setMembshipToMatrix(membship, new_info)\n",
    "        return new_labels, cost\n",
    "    \n",
    "    def fit_predict(self, X, types):\n",
    "        return self.fit(X, types).predict(X, types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_types = [str, float, float, float, float, float, float, str, str, float, float, float, float, float, float, float, float, float, float, float, float, float]\n",
    "ninjaClusters = KModes(n_clusters=int(np.sqrt(a2.shape[0]/2))).fit(a2, a_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_types = [float, str, float, float, str, float, float, float, float, float, float, float, float, str, float, float]\n",
    "h3zmClusters = KModes(n_clusters=int(np.sqrt(b2.shape[0]/2))).fit(b2, b_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ninjaClusters.itr_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
